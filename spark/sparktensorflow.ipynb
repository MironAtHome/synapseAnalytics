{
  "metadata": {
    "language_info": {
      "name": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "import org.apache.commons.io.FileUtils\nimport org.apache.spark.sql.{DataFrame, Row}\nimport org.apache.spark.sql.catalyst.expressions.GenericRow\nimport org.apache.spark.sql.types._"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "import org.apache.commons.io.FileUtils\n",
        "\n",
        "import org.apache.spark.sql.{ DataFrame, Row }\n",
        "import org.apache.spark.sql.catalyst.expressions.GenericRow\n",
        "import org.apache.spark.sql.types._"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "testRows: Array[org.apache.spark.sql.Row] = Array([11,1,23,10.0,14.0,List(1.0, 2.0),r1], [21,2,24,12.0,15.0,List(2.0, 2.0),r2])\nschema: org.apache.spark.sql.types.StructType = StructType(StructField(id,IntegerType,true), StructField(IntegerTypeLabel,IntegerType,true), StructField(LongTypeLabel,LongType,true), StructField(FloatTypeLabel,FloatType,true), StructField(DoubleTypeLabel,DoubleType,true), StructField(VectorLabel,ArrayType(DoubleType,true),true), StructField(name,StringType,true))"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "\n",
        "// Declare DataFrame data\n",
        "val testRows: Array[Row] = Array(\n",
        "  new GenericRow(Array[Any](11, 1, 23L, 10.0F, 14.0, List(1.0, 2.0), \"r1\")),\n",
        "  new GenericRow(Array[Any](21, 2, 24L, 12.0F, 15.0, List(2.0, 2.0), \"r2\"))\n",
        ")\n",
        "\n",
        "// DataFrame schema\n",
        "val schema = StructType(List(StructField(\"id\", IntegerType), \n",
        "                             StructField(\"IntegerTypeLabel\", IntegerType),\n",
        "                             StructField(\"LongTypeLabel\", LongType),\n",
        "                             StructField(\"FloatTypeLabel\", FloatType),\n",
        "                             StructField(\"DoubleTypeLabel\", DoubleType),\n",
        "                             StructField(\"VectorLabel\", ArrayType(DoubleType, true)),\n",
        "                             StructField(\"name\", StringType)))"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "rdd: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = ParallelCollectionRDD[0] at parallelize at <console>:37\ndf: org.apache.spark.sql.DataFrame = [id: int, IntegerTypeLabel: int ... 5 more fields]"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "val rdd = spark.sparkContext.parallelize(testRows)\n",
        "val df: DataFrame = spark.createDataFrame(rdd, schema)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "+---+----------------+-------------+--------------+---------------+-----------+----+\n| id|IntegerTypeLabel|LongTypeLabel|FloatTypeLabel|DoubleTypeLabel|VectorLabel|name|\n+---+----------------+-------------+--------------+---------------+-----------+----+\n| 11|               1|           23|          10.0|           14.0| [1.0, 2.0]|  r1|\n| 21|               2|           24|          12.0|           15.0| [2.0, 2.0]|  r2|\n+---+----------------+-------------+--------------+---------------+-----------+----+"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "df.show()"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Error",
          "evalue": "java.lang.ClassNotFoundException: Failed to find data source: tfrecords. Please find packages at http://spark.apache.org/third-party-projects.html",
          "traceback": [
            "Error : java.lang.ClassNotFoundException: Failed to find data source: tfrecords. Please find packages at http://spark.apache.org/third-party-projects.html",
            "  at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:657)\n",
            "  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:245)\n",
            "  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:229)\n",
            "  ... 55 elided\n",
            "Caused by: java.lang.ClassNotFoundException: tfrecords.DefaultSource\n",
            "  at scala.reflect.internal.util.AbstractFileClassLoader.findClass(AbstractFileClassLoader.scala:62)\n",
            "  at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n",
            "  at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n",
            "  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$20$$anonfun$apply$12.apply(DataSource.scala:634)\n",
            "  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$20$$anonfun$apply$12.apply(DataSource.scala:634)\n",
            "  at scala.util.Try$.apply(Try.scala:192)\n",
            "  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$20.apply(DataSource.scala:634)\n",
            "  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$20.apply(DataSource.scala:634)\n",
            "  at scala.util.Try.orElse(Try.scala:84)\n",
            "  at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:634)\n",
            "  ... 57 more\n"
          ]
        }
      ],
      "metadata": {},
      "source": [
        "val path = \"/tmp/test-output.tfrecord\"\n",
        "df.write.format(\"tfrecords\").option(\"recordType\", \"Example\").mode(\"overwrite\").save(path)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Error",
          "evalue": "java.lang.ClassNotFoundException: Failed to find data source: tfrecords. Please find packages at http://spark.apache.org/third-party-projects.html",
          "traceback": [
            "Error : java.lang.ClassNotFoundException: Failed to find data source: tfrecords. Please find packages at http://spark.apache.org/third-party-projects.html",
            "  at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:657)\n",
            "  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:194)\n",
            "  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)\n",
            "  ... 55 elided\n",
            "Caused by: java.lang.ClassNotFoundException: tfrecords.DefaultSource\n",
            "  at scala.reflect.internal.util.AbstractFileClassLoader.findClass(AbstractFileClassLoader.scala:62)\n",
            "  at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n",
            "  at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n",
            "  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$20$$anonfun$apply$12.apply(DataSource.scala:634)\n",
            "  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$20$$anonfun$apply$12.apply(DataSource.scala:634)\n",
            "  at scala.util.Try$.apply(Try.scala:192)\n",
            "  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$20.apply(DataSource.scala:634)\n",
            "  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$20.apply(DataSource.scala:634)\n",
            "  at scala.util.Try.orElse(Try.scala:84)\n",
            "  at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:634)\n",
            "  ... 57 more\n"
          ]
        }
      ],
      "metadata": {},
      "source": [
        "\n",
        "//The DataFrame schema is inferred from the TFRecords if no custom schema is provided.\n",
        "val importedDf1: DataFrame = spark.read.format(\"tfrecords\").option(\"recordType\", \"Example\").load(path)\n",
        "importedDf1.show()\n",
        "\n",
        "//Read TFRecords into DataFrame using custom schema\n",
        "val importedDf2: DataFrame = spark.read.format(\"tfrecords\").schema(schema).load(path)\n",
        "importedDf2.show()"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Error from browser: Error",
          "evalue": "Can't find magic %%sh",
          "traceback": [
            "Error from browser: Error : Can't find magic %%sh",
            "Error: Can't find magic %%sh\n   at s (https://web.azuresynapse.net/assets/external/extensions/a365/0695881fccbf9377d8d6.index.bundle.js:53:265326)\n   at e.prototype.parseMagicOptions (https://web.azuresynapse.net/assets/external/extensions/a365/0695881fccbf9377d8d6.index.bundle.js:53:264760)\n   at Anonymous function (https://web.azuresynapse.net/assets/external/extensions/a365/0695881fccbf9377d8d6.index.bundle.js:278:8491)\n   at Anonymous function (https://web.azuresynapse.net/assets/external/extensions/a365/0695881fccbf9377d8d6.index.bundle.js:35:550419)\n   at e.prototype._trySubscribe (https://web.azuresynapse.net/assets/external/extensions/a365/0695881fccbf9377d8d6.index.bundle.js:16:746825)\n   at e.prototype.subscribe (https://web.azuresynapse.net/assets/external/extensions/a365/0695881fccbf9377d8d6.index.bundle.js:16:746481)\n   at e.prototype.call (https://web.azuresynapse.net/assets/external/extensions/a365/0695881fccbf9377d8d6.index.bundle.js:27:656240)\n   at e.prototype.subscribe (https://web.azuresynapse.net/assets/external/extensions/a365/0695881fccbf9377d8d6.index.bundle.js:16:746481)\n   at t.prototype.connect (https://web.azuresynapse.net/assets/external/extensions/a365/0695881fccbf9377d8d6.index.bundle.js:53:72503)\n   at Anonymous function (https://web.azuresynapse.net/assets/external/extensions/a365/0695881fccbf9377d8d6.index.bundle.js:53:279346)"
          ]
        }
      ],
      "metadata": {},
      "source": [
        "%%sh\n",
        "curl -s http://us.data.yt8m.org/2/video/train/trainIc.tfrecord > /dbfs/tmp/dl/spark-tf-connector/video_level-train-0.tfrecord"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        ""
      ],
      "attachments": {}
    }
  ]
}
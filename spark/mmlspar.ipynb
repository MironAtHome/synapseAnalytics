{
  "metadata": {
    "saveOutput": true,
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {},
      "source": [
        "import mmlspark"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {},
      "source": [
        "triazines = spark.read.format(\"libsvm\")\\\n",
        "    .load(\"wasbs://publicwasb@mmlspark.blob.core.windows.net/triazines.scale.svmlight\")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "records read: 105\nSchema: \nroot\n |-- label: double (nullable = true)\n |-- features: vector (nullable = true)\n\n   label                                           features\n0  0.809  (-0.6, -0.3325, -0.3325, -1.0, -1.0, -1.0, -1....\n1  0.602  (-0.6, 0.0, 0.0, -1.0, -0.3325, -1.0, -1.0, 0....\n2  0.442  (-0.6, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....\n3  0.718  (-0.6, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....\n4  0.697  (-0.6, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....\n5  0.757  (0.2, -0.6675, -1.0, -1.0, -1.0, 0.0, -1.0, 0....\n6  0.900  (0.2, -0.6675, -1.0, -1.0, -1.0, 0.0, -1.0, 0....\n7  0.564  (-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....\n8  0.772  (0.2, -0.6675, -1.0, -1.0, -1.0, 0.0, -1.0, 0....\n9  0.801  (0.2, -0.6675, -1.0, -1.0, -1.0, 0.0, -1.0, 0....\n/opt/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:2103: UserWarning: toPandas attempted Arrow optimization because 'spark.sql.execution.arrow.enabled' is set to true; however, failed by the reason below:\n  Unsupported type in conversion to Arrow: VectorUDT\nAttempting non-optimization as 'spark.sql.execution.arrow.fallback.enabled' is set to true."
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "# print some basic info\n",
        "print(\"records read: \" + str(triazines.count()))\n",
        "print(\"Schema: \")\n",
        "triazines.printSchema()\n",
        "triazines.limit(10).toPandas()"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "metadata": {},
      "source": [
        "train, test = triazines.randomSplit([0.85, 0.15], seed=1)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "metadata": {},
      "source": [
        "from mmlspark.lightgbm import LightGBMRegressor\n",
        "model = LightGBMRegressor(objective='quantile',\n",
        "                          alpha=0.2,\n",
        "                          learningRate=0.3,\n",
        "                          numLeaves=31).fit(train)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "metadata": {},
      "source": [
        "from mmlspark.lightgbm import LightGBMRegressionModel\n",
        "model.saveNativeModel(\"mymodel\")\n",
        "model = LightGBMRegressionModel.loadNativeModelFromFile(\"mymodel\")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "[18.0, 4.0, 8.0, 0.0, 16.0, 16.0, 0.0, 3.0, 2.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 27.0, 27.0, 18.0, 28.0, 28.0, 0.0, 10.0, 0.0, 4.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0]"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "print(model.getFeatureImportances())"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "label    ...     prediction\n0  0.258    ...       0.414115\n1  0.427    ...       0.539532\n2  0.550    ...       0.537624\n3  0.614    ...       0.640256\n4  0.631    ...       0.422801\n5  0.637    ...       0.521593\n6  0.641    ...       0.585361\n7  0.678    ...       0.585361\n8  0.788    ...       0.726604\n9  0.801    ...       0.634850\n\n[10 rows x 3 columns]"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "scoredData = model.transform(test)\n",
        "scoredData.limit(10).toPandas()"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "mean_squared_error         ...           mean_absolute_error\n0            0.014862         ...                      0.107673\n\n[1 rows x 4 columns]\n/home/trusted-service-user/cluster-env/env/lib/python3.6/site-packages/pyarrow/__init__.py:152: UserWarning: pyarrow.open_stream is deprecated, please use pyarrow.ipc.open_stream\n  warnings.warn(\"pyarrow.open_stream is deprecated, please use \""
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from mmlspark.train import ComputeModelStatistics\n",
        "metrics = ComputeModelStatistics(evaluationMetric='regression',\n",
        "                                 labelCol='label',\n",
        "                                 scoresCol='prediction') \\\n",
        "            .transform(scoredData)\n",
        "metrics.toPandas()"
      ],
      "attachments": {}
    }
  ]
}